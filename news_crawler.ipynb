{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping Script for NLP Semantics Final Project\n",
    "\n",
    "In this script, we are scraping the main text from the chosen news articles (listed in `valid_news_article_links.txt`) using the *`NewsPlease`* library. As we scrape the articles, we save the main text in a pandas DataFrame. This allows us to later analyze each data entry and extract sentences containing the keywords relevant to our final project. It is important to note that the articles are sourced from news outlets known to be as reliable as possible and minimally biased, as determined by [Ad Fontes Mediaâ€™s Media Bias Chart](https://adfontesmedia.com/interactive-media-bias-chart/).\n",
    "\n",
    "\\* *[Documentation for NewPlease Library](https://github.com/fhamborg/news-please)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from newsplease import NewsPlease\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# global variables\n",
    "# the source domain and the corresponding news source\n",
    "SOURCE_DOM_CONVERSION = {'www.nbcnews.com':'NBC News', 'www.npr.org':'NPR News', \n",
    "                         'www.voanews.com':'VOA News', 'www.upi.com':'UPI News',\n",
    "                         'www.bbc.com':'BBC News', 'apnews.com':'AP News',}\n",
    "\n",
    "# the path that contains all the links to the chosen news articles\n",
    "FILE_PATH = 'valid_news_article_links.txt'\n",
    "\n",
    "# the target words we are interested extracting sentences from in each article\n",
    "TARGET_WORDS = ['Democrats', 'Democrat', 'Democratic', 'Republicans',\n",
    "                'Republican', 'Liberals', 'Conservatives', ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Main Text from News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "def remove_duplicates(file_path):\n",
    "    '''\n",
    "    remove duplicates from our txt file that contains urls.\n",
    "    '''\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        urls = file.readlines()\n",
    "\n",
    "    # remove duplicates while preserving order\n",
    "    unique_urls = list(dict.fromkeys(url.strip() for url in urls))\n",
    "\n",
    "    # write back unique URLs to the file\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(\"\\n\".join(unique_urls))\n",
    "\n",
    "    print(f'file updated. {len(urls) - len(unique_urls)} duplicates removed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe where we will store the main text and source of the news articles\n",
    "news_articles_df = pd.DataFrame(columns=['main text', 'source'])\n",
    "data_entries = list()\n",
    "\n",
    "# remove duplicates from the file\n",
    "remove_duplicates(FILE_PATH)\n",
    "\n",
    "with open(FILE_PATH, 'r') as file:\n",
    "    for line in file:\n",
    "        url = line.strip()\n",
    "        if url:\n",
    "            try: \n",
    "                article = NewsPlease.from_url(url)\n",
    "                main_text = article.maintext\n",
    "                source = SOURCE_DOM_CONVERSION.get(article.source_domain,\n",
    "                                                   article.source_domain)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scrapping URL: {url} \\nError: {e}\")\n",
    "                main_text = None\n",
    "                source = None\n",
    "\n",
    "            data_entries.append({'main text': main_text, 'source': source})\n",
    "            # timeout to avoid being blocked \n",
    "            time.sleep(6)\n",
    "\n",
    "# insert all the data entries into our dataframe\n",
    "news_articles_df = pd.DataFrame(data_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The incoming Trump administration is consideri...</td>\n",
       "      <td>NBC News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President-elect Donald Trump has announced he'...</td>\n",
       "      <td>NPR News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>President-elect Donald Trump is expected to co...</td>\n",
       "      <td>NPR News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           main text    source\n",
       "0  The incoming Trump administration is consideri...  NBC News\n",
       "1  President-elect Donald Trump has announced he'...  NPR News\n",
       "2  President-elect Donald Trump is expected to co...  NPR News"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape of the dataframe:', news_articles_df.shape)\n",
    "news_articles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning/Selection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i310d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
